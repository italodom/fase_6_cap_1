{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": "# Projeto de Vis√£o Computacional - FarmTech Solutions\n## Sistema de Detec√ß√£o de Objetos usando YOLO\n\n### Objetivo\nDemonstrar o potencial e acur√°cia de um sistema de vis√£o computacional usando YOLOv8 para detec√ß√£o de objetos.\n\n### Dataset\n- **Objeto A**: Gatos (Cat)\n- **Objeto B**: Cachorros (Dog)\n- **Total**: 82 imagens (41 de cada classe)\n- **Divis√£o**: \n  - Treino: 32 imagens por classe\n  - Valida√ß√£o: 4 imagens por classe\n  - Teste: 4 imagens por classe\n\n### Estrutura do Notebook\n1. **Instala√ß√£o e Configura√ß√£o**\n2. **Configura√ß√£o de Caminhos** (Google Drive ou Local)\n3. **Prepara√ß√£o do Dataset**\n4. **Treinamento** (30 e 60 √©pocas)\n5. **Valida√ß√£o**\n6. **Teste**\n7. **An√°lise Comparativa**\n\n### Ambiente de Execu√ß√£o\nEste notebook pode ser executado em:\n- **Google Colab**: Com dataset no Google Drive\n- **Jupyter Local**: Com dataset em pastas locais\n\n---"
  },
  {
   "cell_type": "markdown",
   "id": "secao1",
   "metadata": {},
   "source": [
    "## 1. Instala√ß√£o e Imports\n",
    "\n",
    "Nesta se√ß√£o, vamos instalar as bibliotecas necess√°rias e importar os m√≥dulos que ser√£o utilizados ao longo do projeto."
   ]
  },
  {
   "cell_type": "code",
   "id": "install",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T02:18:37.881477Z",
     "start_time": "2025-10-15T02:18:36.568131Z"
    }
   },
   "source": [
    "# Instala√ß√£o da biblioteca Ultralytics (YOLOv8)\n",
    "# Esta biblioteca fornece uma implementa√ß√£o moderna e eficiente do YOLO\n",
    "!pip install ultralytics -q\n",
    "\n",
    "# Instala√ß√£o do PyYAML para manipula√ß√£o de arquivos de configura√ß√£o\n",
    "!pip install pyyaml -q\n",
    "\n",
    "print(\"Bibliotecas instaladas com sucesso!\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m24.3.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.2\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m24.3.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.2\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "Bibliotecas instaladas com sucesso!\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "imports",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T02:18:37.890114Z",
     "start_time": "2025-10-15T02:18:37.887173Z"
    }
   },
   "source": [
    "# Importa√ß√£o das bibliotecas necess√°rias\n",
    "from ultralytics import YOLO  # Framework YOLO para detec√ß√£o de objetos\n",
    "import yaml  # Manipula√ß√£o de arquivos YAML\n",
    "import os  # Opera√ß√µes com sistema de arquivos\n",
    "import shutil  # Opera√ß√µes avan√ßadas com arquivos\n",
    "from pathlib import Path  # Manipula√ß√£o de caminhos\n",
    "import matplotlib.pyplot as plt  # Visualiza√ß√£o de gr√°ficos\n",
    "from PIL import Image  # Manipula√ß√£o de imagens\n",
    "import glob  # Busca de arquivos por padr√£o\n",
    "import time  # Medi√ß√£o de tempo\n",
    "\n",
    "# Configura√ß√µes de visualiza√ß√£o\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "print(\"Imports realizados com sucesso!\")\n",
    "print(f\"Vers√£o do Ultralytics: {YOLO.__module__}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports realizados com sucesso!\n",
      "Vers√£o do Ultralytics: ultralytics.models.yolo.model\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "id": "secao2",
   "metadata": {},
   "source": "## 2. Configura√ß√£o de Caminhos\n\nEste notebook pode ser executado em dois ambientes diferentes:\n\n### Op√ß√£o 1: Google Colab (com Google Drive)\nSe estiver usando Google Colab, execute a c√©lula abaixo para conectar ao Drive.\nVoc√™ precisar√°:\n1. Clicar no link que aparecer√°\n2. Fazer login na sua conta Google\n3. Autorizar o acesso ao Drive\n4. Copiar o c√≥digo de autoriza√ß√£o\n\n### Op√ß√£o 2: Ambiente Local (Jupyter/VSCode)\nSe estiver rodando localmente, **pule a c√©lula de montagem do Drive** e v√° direto para a configura√ß√£o de caminhos.\nOs caminhos j√° estar√£o configurados para usar as pastas `dataset/` e `labels/` do projeto."
  },
  {
   "cell_type": "code",
   "id": "mount_drive",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T02:18:37.914659Z",
     "start_time": "2025-10-15T02:18:37.909777Z"
    }
   },
   "source": "# Detectar ambiente e montar Google Drive se necess√°rio\nimport os\n\n# Verificar se est√° rodando no Google Colab\ntry:\n    from google.colab import drive\n    IN_COLAB = True\n    print(\"‚úì Ambiente: Google Colab\")\n    print(\"  Montando Google Drive...\\n\")\n    drive.mount('/content/drive')\n    print(\"\\n‚úì Google Drive conectado com sucesso!\")\n    print(\"  Seus arquivos est√£o acess√≠veis em: /content/drive/MyDrive/\")\nexcept ImportError:\n    IN_COLAB = False\n    print(\"‚úì Ambiente: Local (Jupyter/VSCode)\")\n    print(\"  Usando pastas locais do projeto\")\n    print(\"  Dataset: ./dataset/\")\n    print(\"  Labels: ./labels/\")",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Ambiente: Local (Jupyter/VSCode)\n",
      "  Usando pastas locais do projeto\n",
      "  Dataset: ./dataset/\n",
      "  Labels: ./labels/\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "id": "yngznunh5j",
   "source": "## 3. Prepara√ß√£o do Dataset para YOLO\n\nAgora vamos converter o dataset para o formato YOLO. O processo √©:\n\n1. **Verificar** a estrutura do dataset original\n2. **Criar** a estrutura YOLO (images/ e labels/ com train/val/test)\n3. **Copiar** as imagens organizando por split (n√£o por classe)\n4. **Usar labels existentes** quando dispon√≠veis, ou criar automaticamente\n5. **Gerar** o arquivo data.yaml com as configura√ß√µes\n\n**Estrutura esperada (Google Drive ou Local):**\n```\ndataset/\n‚îú‚îÄ‚îÄ cat/\n‚îÇ   ‚îú‚îÄ‚îÄ train/\n‚îÇ   ‚îú‚îÄ‚îÄ validation/\n‚îÇ   ‚îî‚îÄ‚îÄ test/\n‚îî‚îÄ‚îÄ dog/\n    ‚îú‚îÄ‚îÄ train/\n    ‚îú‚îÄ‚îÄ validation/\n    ‚îî‚îÄ‚îÄ test/\n\nlabels/  (opcional - se tiver labels YOLO prontos)\n‚îú‚îÄ‚îÄ 0.txt\n‚îú‚îÄ‚îÄ 1.txt\n‚îî‚îÄ‚îÄ ...\n```\n\n**Estrutura YOLO que ser√° criada:**\n```\nyolo_dataset/\n‚îú‚îÄ‚îÄ images/\n‚îÇ   ‚îú‚îÄ‚îÄ train/  (todas imagens de treino)\n‚îÇ   ‚îú‚îÄ‚îÄ val/    (todas imagens de valida√ß√£o)\n‚îÇ   ‚îî‚îÄ‚îÄ test/   (todas imagens de teste)\n‚îú‚îÄ‚îÄ labels/\n‚îÇ   ‚îú‚îÄ‚îÄ train/  (labels .txt)\n‚îÇ   ‚îú‚îÄ‚îÄ val/    (labels .txt)\n‚îÇ   ‚îî‚îÄ‚îÄ test/   (labels .txt)\n‚îî‚îÄ‚îÄ data.yaml\n```\n\n**Nota:** O notebook detecta automaticamente se est√° no Colab ou local e ajusta os caminhos adequadamente.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "config_dataset",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T02:18:37.956873Z",
     "start_time": "2025-10-15T02:18:37.949307Z"
    }
   },
   "source": "# Configurar caminhos baseado no ambiente\nimport os\n\nif IN_COLAB:\n    # Caminhos para Google Drive\n    # IMPORTANTE: Ajuste os caminhos abaixo para sua estrutura no Drive!\n    DATASET_SOURCE = '/content/drive/MyDrive/dataset'  # ‚¨ÖÔ∏è AJUSTE AQUI se necess√°rio!\n    LABELS_SOURCE = '/content/drive/MyDrive/labels'    # ‚¨ÖÔ∏è AJUSTE AQUI se necess√°rio!\nelse:\n    # Caminhos locais (relativo ao notebook)\n    BASE_DIR = os.getcwd()\n    DATASET_SOURCE = os.path.join(BASE_DIR, 'dataset')\n    LABELS_SOURCE = os.path.join(BASE_DIR, 'labels')\n\nprint(f\"üìÅ Pasta do dataset: {DATASET_SOURCE}\")\nprint(f\"üìÅ Pasta dos labels: {LABELS_SOURCE}\")\n\n# Verificar se as pastas existem\nif not os.path.exists(DATASET_SOURCE):\n    print(f\"\\n‚ùå ERRO: Pasta dataset n√£o encontrada!\")\n    print(f\"   Caminho: {DATASET_SOURCE}\")\n    \n    if IN_COLAB:\n        print(f\"\\n   Conte√∫do de MyDrive:\")\n        if os.path.exists('/content/drive/MyDrive'):\n            for item in os.listdir('/content/drive/MyDrive')[:10]:\n                print(f\"     - {item}\")\n    else:\n        print(f\"\\n   Conte√∫do do diret√≥rio atual:\")\n        for item in os.listdir('.')[:10]:\n            print(f\"     - {item}\")\nelse:\n    print(f\"\\n‚úì Dataset encontrado!\")\n    \n    # Verificar estrutura\n    classes = ['cat', 'dog']\n    \n    print(\"\\nVerificando estrutura do dataset:\")\n    for class_name in classes:\n        class_path = f\"{DATASET_SOURCE}/{class_name}\"\n        if os.path.exists(class_path):\n            print(f\"  ‚úì {class_name}/\")\n            for split in ['train', 'validation', 'test']:\n                split_path = f\"{class_path}/{split}\"\n                if os.path.exists(split_path):\n                    n_imgs = len([f for f in os.listdir(split_path) if f.endswith(('.jpg', '.jpeg', '.png'))])\n                    print(f\"    ‚úì {split}/  ({n_imgs} imagens)\")\n                else:\n                    print(f\"    ‚ùå {split}/ (n√£o encontrado)\")\n        else:\n            print(f\"  ‚ùå {class_name}/ (n√£o encontrado)\")\n\n# Verificar labels\nif os.path.exists(LABELS_SOURCE):\n    n_labels = len([f for f in os.listdir(LABELS_SOURCE) if f.endswith('.txt')])\n    print(f\"\\n‚úì Labels encontrados: {n_labels} arquivos .txt\")\n    if n_labels > 0:\n        label_files = [f for f in os.listdir(LABELS_SOURCE) if f.endswith('.txt')]\n        print(f\"   Exemplo: {label_files[0]}\")\nelse:\n    print(f\"\\n‚ö†Ô∏è  Pasta labels n√£o encontrada em: {LABELS_SOURCE}\")\n    print(f\"   Labels ser√£o criados automaticamente (bounding box completo)\")",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Pasta do dataset: /Users/italodom/DESENVOLVIMENTO/ITALO/FIAP/fase_6_cap_1/dataset\n",
      "üìÅ Pasta dos labels: /Users/italodom/DESENVOLVIMENTO/ITALO/FIAP/fase_6_cap_1/labels\n",
      "\n",
      "‚úì Dataset encontrado!\n",
      "\n",
      "Verificando estrutura do dataset:\n",
      "  ‚úì cat/\n",
      "    ‚úì train/  (33 imagens)\n",
      "    ‚úì validation/  (4 imagens)\n",
      "    ‚úì test/  (4 imagens)\n",
      "  ‚úì dog/\n",
      "    ‚úì train/  (33 imagens)\n",
      "    ‚úì validation/  (4 imagens)\n",
      "    ‚úì test/  (4 imagens)\n",
      "\n",
      "‚úì Labels encontrados: 41 arquivos .txt\n",
      "   Exemplo: 29.txt\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "id": "create_yolo_structure",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T02:18:37.988074Z",
     "start_time": "2025-10-15T02:18:37.983749Z"
    }
   },
   "source": "# Criar estrutura YOLO\nif IN_COLAB:\n    # No Colab, criar em /content (tempor√°rio)\n    YOLO_DIR = '/content/yolo_dataset'\nelse:\n    # Localmente, criar na pasta do projeto\n    YOLO_DIR = os.path.join(os.getcwd(), 'yolo_dataset')\n\n# Criar diret√≥rios\nos.makedirs(f'{YOLO_DIR}/images/train', exist_ok=True)\nos.makedirs(f'{YOLO_DIR}/images/val', exist_ok=True)\nos.makedirs(f'{YOLO_DIR}/images/test', exist_ok=True)\nos.makedirs(f'{YOLO_DIR}/labels/train', exist_ok=True)\nos.makedirs(f'{YOLO_DIR}/labels/val', exist_ok=True)\nos.makedirs(f'{YOLO_DIR}/labels/test', exist_ok=True)\n\nprint(\"‚úì Estrutura YOLO criada em:\", YOLO_DIR)\nprint(f\"\\n{YOLO_DIR}/\")\nprint(\"‚îú‚îÄ‚îÄ images/\")\nprint(\"‚îÇ   ‚îú‚îÄ‚îÄ train/\")\nprint(\"‚îÇ   ‚îú‚îÄ‚îÄ val/\")\nprint(\"‚îÇ   ‚îî‚îÄ‚îÄ test/\")\nprint(\"‚îî‚îÄ‚îÄ labels/\")\nprint(\"    ‚îú‚îÄ‚îÄ train/\")\nprint(\"    ‚îú‚îÄ‚îÄ val/\")\nprint(\"    ‚îî‚îÄ‚îÄ test/\")",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Estrutura YOLO criada em: /Users/italodom/DESENVOLVIMENTO/ITALO/FIAP/fase_6_cap_1/yolo_dataset\n",
      "\n",
      "/Users/italodom/DESENVOLVIMENTO/ITALO/FIAP/fase_6_cap_1/yolo_dataset/\n",
      "‚îú‚îÄ‚îÄ images/\n",
      "‚îÇ   ‚îú‚îÄ‚îÄ train/\n",
      "‚îÇ   ‚îú‚îÄ‚îÄ val/\n",
      "‚îÇ   ‚îî‚îÄ‚îÄ test/\n",
      "‚îî‚îÄ‚îÄ labels/\n",
      "    ‚îú‚îÄ‚îÄ train/\n",
      "    ‚îú‚îÄ‚îÄ val/\n",
      "    ‚îî‚îÄ‚îÄ test/\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "id": "convert_dataset",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T02:18:38.094848Z",
     "start_time": "2025-10-15T02:18:38.007058Z"
    }
   },
   "source": [
    "# Fun√ß√£o para criar label YOLO (fallback)\n",
    "def create_default_label(class_id):\n",
    "    \"\"\"\n",
    "    Cria um label YOLO padr√£o.\n",
    "    Usado quando n√£o h√° label pr√©-existente.\n",
    "    Formato: class_id x_center y_center width height (normalizados 0-1)\n",
    "    \"\"\"\n",
    "    return f\"{class_id} 0.5 0.5 1.0 1.0\\n\"\n",
    "\n",
    "def get_label_content(img_filename, labels_source, class_id):\n",
    "    \"\"\"\n",
    "    Busca label existente ou cria um padr√£o.\n",
    "    \"\"\"\n",
    "    # Tentar encontrar label correspondente\n",
    "    base_name = os.path.splitext(img_filename)[0]\n",
    "    label_path = f\"{labels_source}/{base_name}.txt\"\n",
    "    \n",
    "    if os.path.exists(label_path):\n",
    "        # Usar label existente\n",
    "        with open(label_path, 'r') as f:\n",
    "            return f.read()\n",
    "    else:\n",
    "        # Criar label padr√£o\n",
    "        return create_default_label(class_id)\n",
    "\n",
    "# Mapear classes\n",
    "class_mapping = {\n",
    "    'cat': 0,\n",
    "    'dog': 1\n",
    "}\n",
    "\n",
    "print(\"Convertendo dataset para formato YOLO...\\n\")\n",
    "print(f\"Classes: {list(class_mapping.keys())}\\n\")\n",
    "\n",
    "stats = {'train': 0, 'val': 0, 'test': 0}\n",
    "labels_stats = {'existing': 0, 'created': 0}\n",
    "\n",
    "for class_name, class_id in class_mapping.items():\n",
    "    print(f\"Processando classe: {class_name}\")\n",
    "    \n",
    "    for split in ['train', 'validation', 'test']:\n",
    "        # Ajustar nome do split (validation -> val no YOLO)\n",
    "        yolo_split = 'val' if split == 'validation' else split\n",
    "        \n",
    "        source_dir = f\"{DATASET_SOURCE}/{class_name}/{split}\"\n",
    "        \n",
    "        if not os.path.exists(source_dir):\n",
    "            print(f\"  ‚ö†Ô∏è  {split}/ n√£o encontrado\")\n",
    "            continue\n",
    "        \n",
    "        # Processar imagens\n",
    "        files = [f for f in os.listdir(source_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "        \n",
    "        for img_file in files:\n",
    "            # Copiar imagem\n",
    "            src_img = f\"{source_dir}/{img_file}\"\n",
    "            new_name = f\"{class_name}_{img_file}\"\n",
    "            dst_img = f\"{YOLO_DIR}/images/{yolo_split}/{new_name}\"\n",
    "            shutil.copy2(src_img, dst_img)\n",
    "            \n",
    "            # Processar label\n",
    "            label_name = os.path.splitext(new_name)[0] + '.txt'\n",
    "            dst_label = f\"{YOLO_DIR}/labels/{yolo_split}/{label_name}\"\n",
    "            \n",
    "            # Buscar label existente ou criar padr√£o\n",
    "            label_content = get_label_content(img_file, LABELS_SOURCE, class_id)\n",
    "            \n",
    "            # Verificar se usou label existente ou criou novo\n",
    "            base_name = os.path.splitext(img_file)[0]\n",
    "            if os.path.exists(f\"{LABELS_SOURCE}/{base_name}.txt\"):\n",
    "                labels_stats['existing'] += 1\n",
    "            else:\n",
    "                labels_stats['created'] += 1\n",
    "            \n",
    "            # Salvar label\n",
    "            with open(dst_label, 'w') as f:\n",
    "                f.write(label_content)\n",
    "            \n",
    "            stats[yolo_split] += 1\n",
    "        \n",
    "        print(f\"  ‚úì {split}: {len(files)} imagens\")\n",
    "\n",
    "print(f\"\\n‚úÖ Convers√£o conclu√≠da!\")\n",
    "print(f\"   Train: {stats['train']} imagens\")\n",
    "print(f\"   Val: {stats['val']} imagens\")\n",
    "print(f\"   Test: {stats['test']} imagens\")\n",
    "print(f\"   Total: {sum(stats.values())} imagens\")\n",
    "print(f\"\\nüìä Labels:\")\n",
    "print(f\"   Existentes utilizados: {labels_stats['existing']}\")\n",
    "print(f\"   Criados automaticamente: {labels_stats['created']}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convertendo dataset para formato YOLO...\n",
      "\n",
      "Classes: ['cat', 'dog']\n",
      "\n",
      "Processando classe: cat\n",
      "  ‚úì train: 33 imagens\n",
      "  ‚úì validation: 4 imagens\n",
      "  ‚úì test: 4 imagens\n",
      "Processando classe: dog\n",
      "  ‚úì train: 33 imagens\n",
      "  ‚úì validation: 4 imagens\n",
      "  ‚úì test: 4 imagens\n",
      "\n",
      "‚úÖ Convers√£o conclu√≠da!\n",
      "   Train: 66 imagens\n",
      "   Val: 8 imagens\n",
      "   Test: 8 imagens\n",
      "   Total: 82 imagens\n",
      "\n",
      "üìä Labels:\n",
      "   Existentes utilizados: 82\n",
      "   Criados automaticamente: 0\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "id": "create_data_yaml",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T02:18:38.106389Z",
     "start_time": "2025-10-15T02:18:38.100441Z"
    }
   },
   "source": [
    "# Criar arquivo data.yaml\n",
    "data_yaml = {\n",
    "    'path': YOLO_DIR,\n",
    "    'train': 'images/train',\n",
    "    'val': 'images/val',\n",
    "    'test': 'images/test',\n",
    "    'nc': 2,\n",
    "    'names': ['cat', 'dog']  # Gato e Cachorro\n",
    "}\n",
    "\n",
    "yaml_path = f'{YOLO_DIR}/data.yaml'\n",
    "\n",
    "with open(yaml_path, 'w') as f:\n",
    "    yaml.dump(data_yaml, f, sort_keys=False)\n",
    "\n",
    "print(\"‚úì Arquivo data.yaml criado!\")\n",
    "print(f\"   Localiza√ß√£o: {yaml_path}\\n\")\n",
    "print(\"Conte√∫do:\")\n",
    "with open(yaml_path, 'r') as f:\n",
    "    print(f.read())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Arquivo data.yaml criado!\n",
      "   Localiza√ß√£o: /Users/italodom/DESENVOLVIMENTO/ITALO/FIAP/fase_6_cap_1/yolo_dataset/data.yaml\n",
      "\n",
      "Conte√∫do:\n",
      "path: /Users/italodom/DESENVOLVIMENTO/ITALO/FIAP/fase_6_cap_1/yolo_dataset\n",
      "train: images/train\n",
      "val: images/val\n",
      "test: images/test\n",
      "nc: 2\n",
      "names:\n",
      "- cat\n",
      "- dog\n",
      "\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "id": "mxjlzdfpoqt",
   "source": "## 4. Treinamento do Modelo YOLO\n\nAgora vamos treinar o modelo YOLOv8 com duas configura√ß√µes diferentes de √©pocas:\n- **Simula√ß√£o 1**: 30 √©pocas\n- **Simula√ß√£o 2**: 60 √©pocas\n\nO treinamento ir√°:\n1. Baixar o modelo pr√©-treinado YOLOv8n (nano - mais leve e r√°pido)\n2. Fazer o fine-tuning com nosso dataset\n3. Salvar os resultados em `runs/detect/train_30epochs` e `runs/detect/train_60epochs`",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "744sqwtddxt",
   "source": "# Simula√ß√£o 1: Treinamento com 30 √©pocas\nprint(\"=\"*60)\nprint(\"SIMULA√á√ÉO 1: Treinamento com 30 √©pocas\")\nprint(\"=\"*60)\n\n# Registrar tempo inicial\nstart_time_30 = time.time()\n\n# Carregar modelo pr√©-treinado\nmodel_30 = YOLO('yolov8n.pt')\n\n# Treinar o modelo\nresults_30 = model_30.train(\n    data=yaml_path,\n    epochs=30,\n    imgsz=640,\n    batch=8,\n    name='train_30epochs',\n    patience=50,\n    save=True,\n    plots=True,\n    verbose=True\n)\n\n# Calcular tempo de treinamento\ntraining_time_30 = time.time() - start_time_30\n\nprint(f\"\\n‚úì Treinamento com 30 √©pocas conclu√≠do!\")\nprint(f\"‚è±Ô∏è  Tempo de treinamento: {training_time_30:.2f} segundos ({training_time_30/60:.2f} minutos)\")\nprint(f\"üìÅ Resultados salvos em: runs/detect/train_30epochs/\")",
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-10-15T02:18:38.112232Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "SIMULA√á√ÉO 1: Treinamento com 30 √©pocas\n",
      "============================================================\n",
      "Ultralytics 8.3.214 üöÄ Python-3.13.5 torch-2.8.0 CPU (Apple M3 Pro)\n",
      "\u001B[34m\u001B[1mengine/trainer: \u001B[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/Users/italodom/DESENVOLVIMENTO/ITALO/FIAP/fase_6_cap_1/yolo_dataset/data.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=30, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train_30epochs2, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=50, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/Users/italodom/DESENVOLVIMENTO/ITALO/FIAP/fase_6_cap_1/runs/detect/train_30epochs2, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    751702  ultralytics.nn.modules.head.Detect           [2, [64, 128, 256]]           \n",
      "Model summary: 129 layers, 3,011,238 parameters, 3,011,222 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 888.4¬±426.4 MB/s, size: 25.6 KB)\n",
      "\u001B[K\u001B[34m\u001B[1mtrain: \u001B[0mScanning /Users/italodom/DESENVOLVIMENTO/ITALO/FIAP/fase_6_cap_1/yolo_dataset/labels/train.cache... 66 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 66/66 118.9Kit/s 0.0s\n",
      "\u001B[34m\u001B[1mval: \u001B[0mFast image access ‚úÖ (ping: 0.1¬±0.1 ms, read: 522.5¬±486.4 MB/s, size: 30.3 KB)\n",
      "\u001B[K\u001B[34m\u001B[1mval: \u001B[0mScanning /Users/italodom/DESENVOLVIMENTO/ITALO/FIAP/fase_6_cap_1/yolo_dataset/labels/val.cache... 8 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 24.2Kit/s 0.0s\n",
      "Plotting labels to /Users/italodom/DESENVOLVIMENTO/ITALO/FIAP/fase_6_cap_1/runs/detect/train_30epochs2/labels.jpg... \n",
      "\u001B[34m\u001B[1moptimizer:\u001B[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001B[34m\u001B[1moptimizer:\u001B[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001B[1m/Users/italodom/DESENVOLVIMENTO/ITALO/FIAP/fase_6_cap_1/runs/detect/train_30epochs2\u001B[0m\n",
      "Starting training for 30 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001B[K       1/30         0G        1.4       3.02      1.921          3        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 0.4it/s 25.1s1.4ss\n",
      "\u001B[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.4it/s 0.7s\n",
      "                   all          8          8    0.00586          1      0.641      0.297\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "83jzb01lkfh",
   "source": "# Simula√ß√£o 2: Treinamento com 60 √©pocas\nprint(\"\\n\" + \"=\"*60)\nprint(\"SIMULA√á√ÉO 2: Treinamento com 60 √©pocas\")\nprint(\"=\"*60)\n\n# Registrar tempo inicial\nstart_time_60 = time.time()\n\n# Carregar modelo pr√©-treinado (novo modelo)\nmodel_60 = YOLO('yolov8n.pt')\n\n# Treinar o modelo\nresults_60 = model_60.train(\n    data=yaml_path,\n    epochs=60,\n    imgsz=640,\n    batch=8,\n    name='train_60epochs',\n    patience=50,\n    save=True,\n    plots=True,\n    verbose=True\n)\n\n# Calcular tempo de treinamento\ntraining_time_60 = time.time() - start_time_60\n\nprint(f\"\\n‚úì Treinamento com 60 √©pocas conclu√≠do!\")\nprint(f\"‚è±Ô∏è  Tempo de treinamento: {training_time_60:.2f} segundos ({training_time_60/60:.2f} minutos)\")\nprint(f\"üìÅ Resultados salvos em: runs/detect/train_60epochs/\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "4xur07mln46",
   "source": "## 5. Valida√ß√£o dos Modelos\n\nVamos validar ambos os modelos treinados no conjunto de valida√ß√£o para comparar suas m√©tricas de performance:\n- **mAP50**: Mean Average Precision com IoU threshold de 0.5\n- **mAP50-95**: Mean Average Precision com IoU thresholds de 0.5 a 0.95\n- **Precision**: Precis√£o das detec√ß√µes\n- **Recall**: Taxa de recupera√ß√£o dos objetos",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "woq6n8i148",
   "source": "# Valida√ß√£o do modelo com 30 √©pocas\nprint(\"=\"*60)\nprint(\"VALIDA√á√ÉO - Modelo 30 √©pocas\")\nprint(\"=\"*60)\n\n# Carregar o melhor modelo treinado\nmodel_30_best = YOLO('runs/detect/train_30epochs/weights/best.pt')\n\n# Executar valida√ß√£o\nmetrics_30 = model_30_best.val(data=yaml_path)\n\nprint(f\"\\nüìä M√©tricas do Modelo (30 √©pocas):\")\nprint(f\"   mAP50: {metrics_30.box.map50:.4f}\")\nprint(f\"   mAP50-95: {metrics_30.box.map:.4f}\")\nprint(f\"   Precision: {metrics_30.box.mp:.4f}\")\nprint(f\"   Recall: {metrics_30.box.mr:.4f}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "gt80thegic5",
   "source": "# Valida√ß√£o do modelo com 60 √©pocas\nprint(\"\\n\" + \"=\"*60)\nprint(\"VALIDA√á√ÉO - Modelo 60 √©pocas\")\nprint(\"=\"*60)\n\n# Carregar o melhor modelo treinado\nmodel_60_best = YOLO('runs/detect/train_60epochs/weights/best.pt')\n\n# Executar valida√ß√£o\nmetrics_60 = model_60_best.val(data=yaml_path)\n\nprint(f\"\\nüìä M√©tricas do Modelo (60 √©pocas):\")\nprint(f\"   mAP50: {metrics_60.box.map50:.4f}\")\nprint(f\"   mAP50-95: {metrics_60.box.map:.4f}\")\nprint(f\"   Precision: {metrics_60.box.mp:.4f}\")\nprint(f\"   Recall: {metrics_60.box.mr:.4f}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "86d8tcwbx4a",
   "source": "## 6. Teste dos Modelos\n\nAgora vamos testar ambos os modelos nas imagens de teste (que o modelo nunca viu durante o treinamento) e visualizar os resultados.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "mar7dj1kbhg",
   "source": "# Teste do modelo com 30 √©pocas\nprint(\"=\"*60)\nprint(\"TESTE - Modelo 30 √©pocas\")\nprint(\"=\"*60)\n\ntest_images_path = f'{YOLO_DIR}/images/test'\n\n# Fazer predi√ß√µes\nresults_test_30 = model_30_best.predict(\n    source=test_images_path,\n    save=True,\n    project='runs/detect',\n    name='test_30epochs',\n    conf=0.25\n)\n\nprint(f\"‚úì Predi√ß√µes realizadas e salvas em: runs/detect/test_30epochs/\")\nprint(f\"   Total de imagens processadas: {len(results_test_30)}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "vqrmo3uxv4j",
   "source": "# Teste do modelo com 60 √©pocas\nprint(\"\\n\" + \"=\"*60)\nprint(\"TESTE - Modelo 60 √©pocas\")\nprint(\"=\"*60)\n\n# Fazer predi√ß√µes\nresults_test_60 = model_60_best.predict(\n    source=test_images_path,\n    save=True,\n    project='runs/detect',\n    name='test_60epochs',\n    conf=0.25\n)\n\nprint(f\"‚úì Predi√ß√µes realizadas e salvas em: runs/detect/test_60epochs/\")\nprint(f\"   Total de imagens processadas: {len(results_test_60)}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "2iv13obx39c",
   "source": "# Visualizar algumas imagens de teste processadas\ndef show_predictions(results_path, title, num_images=4):\n    \"\"\"Mostra imagens com as predi√ß√µes\"\"\"\n    images = glob.glob(f'{results_path}/*.jpg') + glob.glob(f'{results_path}/*.jpeg') + glob.glob(f'{results_path}/*.png')\n    images = images[:num_images]\n    \n    if not images:\n        print(f\"‚ö†Ô∏è  Nenhuma imagem encontrada em {results_path}\")\n        return\n    \n    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n    fig.suptitle(title, fontsize=16, fontweight='bold')\n    \n    for idx, img_path in enumerate(images[:4]):\n        row = idx // 2\n        col = idx % 2\n        \n        img = Image.open(img_path)\n        axes[row, col].imshow(img)\n        axes[row, col].set_title(os.path.basename(img_path))\n        axes[row, col].axis('off')\n    \n    plt.tight_layout()\n    plt.show()\n\nprint(\"Visualizando resultados do modelo com 30 √©pocas:\")\nshow_predictions('runs/detect/test_30epochs', 'Predi√ß√µes - Modelo 30 √âpocas')",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "5crmc9ory3b",
   "source": "print(\"Visualizando resultados do modelo com 60 √©pocas:\")\nshow_predictions('runs/detect/test_60epochs', 'Predi√ß√µes - Modelo 60 √âpocas')",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "xdezwymrth",
   "source": "## 7. An√°lise Comparativa e Conclus√µes\n\nVamos comparar os resultados das duas simula√ß√µes e apresentar conclus√µes sobre os pontos fortes e limita√ß√µes de cada abordagem.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "ufd4jgh72fr",
   "source": "# Tabela comparativa\nimport pandas as pd\n\ncomparison_data = {\n    'M√©trica': ['√âpocas', 'Tempo de Treinamento (min)', 'mAP50', 'mAP50-95', 'Precision', 'Recall'],\n    'Modelo 30 √âpocas': [\n        30,\n        f'{training_time_30/60:.2f}',\n        f'{metrics_30.box.map50:.4f}',\n        f'{metrics_30.box.map:.4f}',\n        f'{metrics_30.box.mp:.4f}',\n        f'{metrics_30.box.mr:.4f}'\n    ],\n    'Modelo 60 √âpocas': [\n        60,\n        f'{training_time_60/60:.2f}',\n        f'{metrics_60.box.map50:.4f}',\n        f'{metrics_60.box.map:.4f}',\n        f'{metrics_60.box.mp:.4f}',\n        f'{metrics_60.box.mr:.4f}'\n    ]\n}\n\ndf_comparison = pd.DataFrame(comparison_data)\n\nprint(\"=\"*80)\nprint(\"COMPARA√á√ÉO ENTRE OS MODELOS\")\nprint(\"=\"*80)\nprint(df_comparison.to_string(index=False))\nprint(\"=\"*80)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "39qepytzh3b",
   "source": "### An√°lise dos Resultados\n\n#### Compara√ß√£o de Performance\n\n**Tempo de Treinamento:**\n- O modelo com 60 √©pocas levou aproximadamente o dobro do tempo do modelo com 30 √©pocas, como esperado\n- Importante considerar o custo computacional vs. ganho de performance\n\n**M√©tricas de Acur√°cia:**\n- **mAP50**: Mede a precis√£o m√©dia com IoU threshold de 0.5\n- **mAP50-95**: M√©trica mais rigorosa que varia o threshold de 0.5 a 0.95\n- **Precision**: Propor√ß√£o de detec√ß√µes corretas entre todas as detec√ß√µes\n- **Recall**: Propor√ß√£o de objetos detectados entre todos os objetos reais\n\n#### Pontos Fortes\n\n**Modelo 30 √âpocas:**\n- ‚úÖ Treinamento mais r√°pido\n- ‚úÖ Menor custo computacional\n- ‚úÖ Bom para prototipagem e testes r√°pidos\n- ‚úÖ Pode ser suficiente para datasets simples\n\n**Modelo 60 √âpocas:**\n- ‚úÖ Potencialmente maior acur√°cia\n- ‚úÖ Melhor converg√™ncia do modelo\n- ‚úÖ Reduz risco de underfitting\n- ‚úÖ Recomendado para aplica√ß√µes em produ√ß√£o\n\n#### Limita√ß√µes\n\n**Modelo 30 √âpocas:**\n- ‚ö†Ô∏è Pode n√£o convergir completamente\n- ‚ö†Ô∏è Risco de underfitting em datasets complexos\n- ‚ö†Ô∏è Menor generaliza√ß√£o\n\n**Modelo 60 √âpocas:**\n- ‚ö†Ô∏è Maior tempo de treinamento\n- ‚ö†Ô∏è Maior consumo de recursos computacionais\n- ‚ö†Ô∏è Risco de overfitting se n√£o houver regulariza√ß√£o adequada\n- ‚ö†Ô∏è Pode n√£o trazer ganhos significativos em datasets simples\n\n#### Recomenda√ß√µes\n\n1. **Para este dataset (Cat vs Dog):**\n   - Dataset relativamente simples com classes bem distintas\n   - Ambos os modelos provavelmente ter√£o boa performance\n   - A diferen√ßa de acur√°cia pode n√£o justificar o dobro do tempo de treinamento\n\n2. **Em produ√ß√£o:**\n   - Come√ßar com 30 √©pocas para baseline\n   - Aumentar √©pocas se m√©tricas de valida√ß√£o continuarem melhorando\n   - Usar early stopping para evitar overfitting\n   - Considerar augmentation de dados para melhorar generaliza√ß√£o\n\n3. **Trade-off Tempo vs. Acur√°cia:**\n   - Avaliar se o ganho de performance justifica o tempo adicional\n   - Para aplica√ß√µes em tempo real, considerar modelos mais leves (YOLOv8n)\n   - Para alta precis√£o, considerar modelos maiores (YOLOv8m, YOLOv8l)",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "id": "wxm4obrlmnk",
   "source": "### Conclus√£o Final\n\nEste projeto demonstrou com sucesso a implementa√ß√£o e compara√ß√£o de um sistema de vis√£o computacional usando YOLOv8 para detec√ß√£o de objetos (gatos e cachorros).\n\n**Principais Aprendizados:**\n\n1. **Prepara√ß√£o de Dados**: O formato YOLO requer estrutura espec√≠fica de pastas e arquivos de anota√ß√£o normalizados\n\n2. **Treinamento**: O YOLOv8 facilita o processo com API simples, mas √© crucial escolher hiperpar√¢metros adequados\n\n3. **Valida√ß√£o**: M√©tricas como mAP50 e Precision/Recall s√£o essenciais para avaliar a qualidade do modelo\n\n4. **Teste**: Visualizar predi√ß√µes em imagens nunca vistas valida a capacidade de generaliza√ß√£o\n\n5. **Trade-offs**: A escolha entre 30 e 60 √©pocas depende do contexto: tempo dispon√≠vel, recursos computacionais e requisitos de acur√°cia\n\n**Aplica√ß√µes Pr√°ticas (FarmTech Solutions):**\n- Monitoramento de animais em fazendas\n- Controle de acesso baseado em reconhecimento\n- An√°lise de documentos com detec√ß√£o de elementos\n- Seguran√ßa patrimonial com detec√ß√£o de intrusos\n\n---\n\n**Desenvolvido para FarmTech Solutions** ü§ñüöú",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
