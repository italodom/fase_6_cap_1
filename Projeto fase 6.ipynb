{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "authorship_tag": "ABX9TyP6EcSciSV/YARytL/MSSoS"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9mx7P73c21Uz",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1760414378558,
     "user_tz": 180,
     "elapsed": 24531,
     "user": {
      "displayName": "Maison Wendrel",
      "userId": "09937109300817250136"
     }
    },
    "outputId": "6b6eb171-e631-4cbb-b264-d7f33c1f71aa",
    "ExecuteTime": {
     "end_time": "2025-10-14T23:59:46.979113Z",
     "start_time": "2025-10-14T23:58:12.298316Z"
    }
   },
   "source": [
    "# Instalar Ultralytics (YOLOv8)\n",
    "!pip install ultralytics\n",
    "\n",
    "# Instalar PyYAML para manipular arquivos YAML\n",
    "!pip install pyyaml\n",
    "\n",
    "# Importar bibliotecas\n",
    "from ultralytics import YOLO\n",
    "import yaml\n",
    "import os"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ultralytics\r\n",
      "  Downloading ultralytics-8.3.214-py3-none-any.whl.metadata (37 kB)\r\n",
      "Collecting numpy>=1.23.0 (from ultralytics)\r\n",
      "  Using cached numpy-2.3.3-cp313-cp313-macosx_14_0_arm64.whl.metadata (62 kB)\r\n",
      "Collecting matplotlib>=3.3.0 (from ultralytics)\r\n",
      "  Downloading matplotlib-3.10.7-cp313-cp313-macosx_11_0_arm64.whl.metadata (11 kB)\r\n",
      "Collecting opencv-python>=4.6.0 (from ultralytics)\r\n",
      "  Downloading opencv_python-4.12.0.88-cp37-abi3-macosx_13_0_arm64.whl.metadata (19 kB)\r\n",
      "Collecting pillow>=7.1.2 (from ultralytics)\r\n",
      "  Using cached pillow-11.3.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (9.0 kB)\r\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in ./.venv/lib/python3.13/site-packages (from ultralytics) (6.0.3)\r\n",
      "Requirement already satisfied: requests>=2.23.0 in ./.venv/lib/python3.13/site-packages (from ultralytics) (2.32.5)\r\n",
      "Collecting scipy>=1.4.1 (from ultralytics)\r\n",
      "  Downloading scipy-1.16.2-cp313-cp313-macosx_14_0_arm64.whl.metadata (62 kB)\r\n",
      "Collecting torch>=1.8.0 (from ultralytics)\r\n",
      "  Downloading torch-2.8.0-cp313-none-macosx_11_0_arm64.whl.metadata (30 kB)\r\n",
      "Collecting torchvision>=0.9.0 (from ultralytics)\r\n",
      "  Downloading torchvision-0.23.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (6.1 kB)\r\n",
      "Requirement already satisfied: psutil in ./.venv/lib/python3.13/site-packages (from ultralytics) (7.1.0)\r\n",
      "Collecting polars (from ultralytics)\r\n",
      "  Downloading polars-1.34.0-py3-none-any.whl.metadata (10 kB)\r\n",
      "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\r\n",
      "  Downloading ultralytics_thop-2.0.17-py3-none-any.whl.metadata (14 kB)\r\n",
      "Collecting contourpy>=1.0.1 (from matplotlib>=3.3.0->ultralytics)\r\n",
      "  Using cached contourpy-1.3.3-cp313-cp313-macosx_11_0_arm64.whl.metadata (5.5 kB)\r\n",
      "Collecting cycler>=0.10 (from matplotlib>=3.3.0->ultralytics)\r\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\r\n",
      "Collecting fonttools>=4.22.0 (from matplotlib>=3.3.0->ultralytics)\r\n",
      "  Downloading fonttools-4.60.1-cp313-cp313-macosx_10_13_universal2.whl.metadata (112 kB)\r\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib>=3.3.0->ultralytics)\r\n",
      "  Using cached kiwisolver-1.4.9-cp313-cp313-macosx_11_0_arm64.whl.metadata (6.3 kB)\r\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.13/site-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\r\n",
      "Collecting pyparsing>=3 (from matplotlib>=3.3.0->ultralytics)\r\n",
      "  Downloading pyparsing-3.2.5-py3-none-any.whl.metadata (5.0 kB)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./.venv/lib/python3.13/site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\r\n",
      "Collecting numpy>=1.23.0 (from ultralytics)\r\n",
      "  Downloading numpy-2.2.6-cp313-cp313-macosx_14_0_arm64.whl.metadata (62 kB)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.13/site-packages (from requests>=2.23.0->ultralytics) (3.4.4)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.13/site-packages (from requests>=2.23.0->ultralytics) (3.11)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.13/site-packages (from requests>=2.23.0->ultralytics) (2.5.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.13/site-packages (from requests>=2.23.0->ultralytics) (2025.10.5)\r\n",
      "Collecting filelock (from torch>=1.8.0->ultralytics)\r\n",
      "  Using cached filelock-3.20.0-py3-none-any.whl.metadata (2.1 kB)\r\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in ./.venv/lib/python3.13/site-packages (from torch>=1.8.0->ultralytics) (4.15.0)\r\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.13/site-packages (from torch>=1.8.0->ultralytics) (80.9.0)\r\n",
      "Collecting sympy>=1.13.3 (from torch>=1.8.0->ultralytics)\r\n",
      "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\r\n",
      "Collecting networkx (from torch>=1.8.0->ultralytics)\r\n",
      "  Using cached networkx-3.5-py3-none-any.whl.metadata (6.3 kB)\r\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.13/site-packages (from torch>=1.8.0->ultralytics) (3.1.6)\r\n",
      "Collecting fsspec (from torch>=1.8.0->ultralytics)\r\n",
      "  Using cached fsspec-2025.9.0-py3-none-any.whl.metadata (10 kB)\r\n",
      "Collecting polars-runtime-32==1.34.0 (from polars->ultralytics)\r\n",
      "  Downloading polars_runtime_32-1.34.0-cp39-abi3-macosx_11_0_arm64.whl.metadata (1.5 kB)\r\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.13/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\r\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch>=1.8.0->ultralytics)\r\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.13/site-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.3)\r\n",
      "Downloading ultralytics-8.3.214-py3-none-any.whl (1.1 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.1/1.1 MB\u001B[0m \u001B[31m9.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading matplotlib-3.10.7-cp313-cp313-macosx_11_0_arm64.whl (8.1 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m8.1/8.1 MB\u001B[0m \u001B[31m9.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m:00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading opencv_python-4.12.0.88-cp37-abi3-macosx_13_0_arm64.whl (37.9 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m37.9/37.9 MB\u001B[0m \u001B[31m10.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading numpy-2.2.6-cp313-cp313-macosx_14_0_arm64.whl (5.1 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m5.1/5.1 MB\u001B[0m \u001B[31m9.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0mm\r\n",
      "\u001B[?25hUsing cached pillow-11.3.0-cp313-cp313-macosx_11_0_arm64.whl (4.7 MB)\r\n",
      "Downloading scipy-1.16.2-cp313-cp313-macosx_14_0_arm64.whl (20.9 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m20.9/20.9 MB\u001B[0m \u001B[31m8.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading torch-2.8.0-cp313-none-macosx_11_0_arm64.whl (73.6 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m73.6/73.6 MB\u001B[0m \u001B[31m9.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0mm\r\n",
      "\u001B[?25hDownloading torchvision-0.23.0-cp313-cp313-macosx_11_0_arm64.whl (1.9 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.9/1.9 MB\u001B[0m \u001B[31m10.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading ultralytics_thop-2.0.17-py3-none-any.whl (28 kB)\r\n",
      "Downloading polars-1.34.0-py3-none-any.whl (772 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m772.7/772.7 kB\u001B[0m \u001B[31m11.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading polars_runtime_32-1.34.0-cp39-abi3-macosx_11_0_arm64.whl (36.0 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m36.0/36.0 MB\u001B[0m \u001B[31m9.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0mm\r\n",
      "\u001B[?25hUsing cached contourpy-1.3.3-cp313-cp313-macosx_11_0_arm64.whl (274 kB)\r\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\r\n",
      "Downloading fonttools-4.60.1-cp313-cp313-macosx_10_13_universal2.whl (2.8 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.8/2.8 MB\u001B[0m \u001B[31m4.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hUsing cached kiwisolver-1.4.9-cp313-cp313-macosx_11_0_arm64.whl (64 kB)\r\n",
      "Downloading pyparsing-3.2.5-py3-none-any.whl (113 kB)\r\n",
      "Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\r\n",
      "Using cached filelock-3.20.0-py3-none-any.whl (16 kB)\r\n",
      "Using cached fsspec-2025.9.0-py3-none-any.whl (199 kB)\r\n",
      "Using cached networkx-3.5-py3-none-any.whl (2.0 MB)\r\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\r\n",
      "Installing collected packages: mpmath, sympy, pyparsing, polars-runtime-32, pillow, numpy, networkx, kiwisolver, fsspec, fonttools, filelock, cycler, torch, scipy, polars, opencv-python, contourpy, ultralytics-thop, torchvision, matplotlib, ultralytics\r\n",
      "Successfully installed contourpy-1.3.3 cycler-0.12.1 filelock-3.20.0 fonttools-4.60.1 fsspec-2025.9.0 kiwisolver-1.4.9 matplotlib-3.10.7 mpmath-1.3.0 networkx-3.5 numpy-2.2.6 opencv-python-4.12.0.88 pillow-11.3.0 polars-1.34.0 polars-runtime-32-1.34.0 pyparsing-3.2.5 scipy-1.16.2 sympy-1.14.0 torch-2.8.0 torchvision-0.23.0 ultralytics-8.3.214 ultralytics-thop-2.0.17\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m24.3.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.2\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "Requirement already satisfied: pyyaml in ./.venv/lib/python3.13/site-packages (6.0.3)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m24.3.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.2\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "WARNING ⚠️ Ultralytics settings reset to default values. This may be due to a possible problem with your settings or a recent ultralytics package update. \n",
      "View Ultralytics Settings with 'yolo settings' or at '/Users/italodom/Library/Application Support/Ultralytics/settings.json'\n",
      "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "source": [
    "# Criar estrutura de diretórios\n",
    "os.makedirs('/content/dataset_yolo/images/train', exist_ok=True)\n",
    "os.makedirs('/content/dataset_yolo/images/val', exist_ok=True)\n",
    "os.makedirs('/content/dataset_yolo/images/test', exist_ok=True)\n",
    "\n",
    "os.makedirs('/content/dataset_yolo/labels/train', exist_ok=True)\n",
    "os.makedirs('/content/dataset_yolo/labels/val', exist_ok=True)\n",
    "os.makedirs('/content/dataset_yolo/labels/test', exist_ok=True)"
   ],
   "metadata": {
    "id": "c-K3tKks22vC"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Conteúdo do arquivo data.yaml\n",
    "data_config = {\n",
    "    'train': '/content/dataset_yolo/images/train',\n",
    "    'val': '/content/dataset_yolo/images/val',\n",
    "    'test': '/content/dataset_yolo/images/test',\n",
    "    'nc': 2,\n",
    "    'names': ['A', 'B']\n",
    "}\n",
    "\n",
    "# Salvar o arquivo\n",
    "with open('/content/dataset_yolo/data.yaml', 'w') as f:\n",
    "    yaml.dump(data_config, f)"
   ],
   "metadata": {
    "id": "nVllhEYo22xx"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from google.colab import files\n",
    "uploaded = files.upload()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 316
    },
    "id": "vnKTVwT5220i",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1760414496834,
     "user_tz": 180,
     "elapsed": 21636,
     "user": {
      "displayName": "Maison Wendrel",
      "userId": "09937109300817250136"
     }
    },
    "outputId": "b8c83fe4-18bd-41b3-9bda-bd0cb9aa542d"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-beee99a7-254c-4f6c-aa9f-986bc2494706\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-beee99a7-254c-4f6c-aa9f-986bc2494706\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Saving Leão 1.jpg to Leão 1.jpg\n",
      "Saving leao 2.jpg to leao 2.jpg\n",
      "Saving leão 3.jpeg to leão 3.jpeg\n",
      "Saving leao 4 .jpg to leao 4 .jpg\n",
      "Saving tigre 1.jpeg to tigre 1.jpeg\n",
      "Saving tigre 2.jpeg to tigre 2.jpeg\n",
      "Saving tigre 3 - Copia.jpeg to tigre 3 - Copia (1).jpeg\n",
      "Saving tigre 3.jpeg to tigre 3.jpeg\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from google.colab import files\n",
    "uploaded = files.upload()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "H_Zmgpap4YpG",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1760414602613,
     "user_tz": 180,
     "elapsed": 53240,
     "user": {
      "displayName": "Maison Wendrel",
      "userId": "09937109300817250136"
     }
    },
    "outputId": "6c28388e-75a5-4cd7-9995-de37d7f46a16"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-a058b232-6773-42ec-bd33-48af8de02254\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-a058b232-6773-42ec-bd33-48af8de02254\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Saving leao 9.jpeg to leao 9.jpeg\n",
      "Saving leão 10.jpeg to leão 10.jpeg\n",
      "Saving leao 11.jpeg to leao 11.jpeg\n",
      "Saving leão 12.jpeg to leão 12.jpeg\n",
      "Saving leão 13.jpeg to leão 13.jpeg\n",
      "Saving leão 14.jpeg to leão 14.jpeg\n",
      "Saving leão 15.jpeg to leão 15.jpeg\n",
      "Saving leão 16.jpeg to leão 16.jpeg\n",
      "Saving leão 17.jpeg to leão 17.jpeg\n",
      "Saving leão 18.jpeg to leão 18.jpeg\n",
      "Saving leao 19.jpeg to leao 19.jpeg\n",
      "Saving leão 20.jpg to leão 20.jpg\n",
      "Saving leão 21.jpeg to leão 21.jpeg\n",
      "Saving leão 22.jpeg to leão 22.jpeg\n",
      "Saving leao 23.jpeg to leao 23.jpeg\n",
      "Saving leão 24.jpeg to leão 24.jpeg\n",
      "Saving leão 25.jpeg to leão 25.jpeg\n",
      "Saving leão 26.jpeg to leão 26.jpeg\n",
      "Saving leão 27.jpeg to leão 27.jpeg\n",
      "Saving leão 28.jpeg to leão 28.jpeg\n",
      "Saving leão 29.jpeg to leão 29.jpeg\n",
      "Saving leão 30.jpeg to leão 30.jpeg\n",
      "Saving leão 31.jpeg to leão 31.jpeg\n",
      "Saving leão 32.jpeg to leão 32.jpeg\n",
      "Saving leão 33.jpeg to leão 33.jpeg\n",
      "Saving leão 34.jpeg to leão 34.jpeg\n",
      "Saving leão 35.jpeg to leão 35.jpeg\n",
      "Saving leão 36.jpeg to leão 36.jpeg\n",
      "Saving leão 37.jpeg to leão 37.jpeg\n",
      "Saving leão 38.jpeg to leão 38.jpeg\n",
      "Saving leão 39.jpeg to leão 39.jpeg\n",
      "Saving leao 40.jpeg to leao 40.jpeg\n",
      "Saving tigre 9.jpeg to tigre 9.jpeg\n",
      "Saving tigre 10.jpeg to tigre 10.jpeg\n",
      "Saving tigre 11.jpeg to tigre 11.jpeg\n",
      "Saving tigre 12.jpeg to tigre 12.jpeg\n",
      "Saving tigre 13.jpeg to tigre 13.jpeg\n",
      "Saving tigre 14.jpeg to tigre 14.jpeg\n",
      "Saving tigre 15.jpeg to tigre 15.jpeg\n",
      "Saving tigre 16.jpeg to tigre 16.jpeg\n",
      "Saving tigre 17.jpeg to tigre 17.jpeg\n",
      "Saving tigre 18.jpeg to tigre 18.jpeg\n",
      "Saving tigre 19.jpeg to tigre 19.jpeg\n",
      "Saving tigre 20.jpeg to tigre 20.jpeg\n",
      "Saving tigre 21.jpeg to tigre 21.jpeg\n",
      "Saving tigre 22.jpeg to tigre 22.jpeg\n",
      "Saving tigre 23.jpeg to tigre 23.jpeg\n",
      "Saving tigre 24.jpeg to tigre 24.jpeg\n",
      "Saving tigre 25.jpeg to tigre 25.jpeg\n",
      "Saving tigre 26.jpeg to tigre 26.jpeg\n",
      "Saving tigre 27.jpeg to tigre 27.jpeg\n",
      "Saving tigre 28.jpeg to tigre 28.jpeg\n",
      "Saving tigre 29.jpeg to tigre 29.jpeg\n",
      "Saving tigre 30.jpeg to tigre 30.jpeg\n",
      "Saving tigre 31.jpeg to tigre 31.jpeg\n",
      "Saving tigre 32.jpeg to tigre 32.jpeg\n",
      "Saving tigre 33.jpeg to tigre 33.jpeg\n",
      "Saving tigre 34.jpeg to tigre 34.jpeg\n",
      "Saving tigre 35.jpeg to tigre 35.jpeg\n",
      "Saving tigre 36.jpeg to tigre 36.jpeg\n",
      "Saving tigre 37.jpeg to tigre 37.jpeg\n",
      "Saving tigre 38.jpeg to tigre 38.jpeg\n",
      "Saving tigre 39.jpeg to tigre 39.jpeg\n",
      "Saving tigre 40.jpeg to tigre 40.jpeg\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from google.colab import files\n",
    "uploaded = files.upload()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 316
    },
    "id": "i2ZzNWQW4rMd",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1760414625099,
     "user_tz": 180,
     "elapsed": 22468,
     "user": {
      "displayName": "Maison Wendrel",
      "userId": "09937109300817250136"
     }
    },
    "outputId": "e856b70c-a61e-45e1-afe0-03a3cf91655b"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-9b38968e-5ebd-443d-bb26-6934fbb17b07\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-9b38968e-5ebd-443d-bb26-6934fbb17b07\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Saving leao 5.jpeg to leao 5.jpeg\n",
      "Saving leão 6 .jpeg to leão 6 .jpeg\n",
      "Saving leão 7 .jpeg to leão 7 .jpeg\n",
      "Saving leão 8.jpeg to leão 8.jpeg\n",
      "Saving tigre 5.jpeg to tigre 5.jpeg\n",
      "Saving tigre 6.jpeg to tigre 6.jpeg\n",
      "Saving tigre 7.jpeg to tigre 7.jpeg\n",
      "Saving tigre 8.jpeg to tigre 8.jpeg\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from google.colab import files\n",
    "uploaded = files.upload()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "pSCLnFE242fR",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1760414705342,
     "user_tz": 180,
     "elapsed": 65523,
     "user": {
      "displayName": "Maison Wendrel",
      "userId": "09937109300817250136"
     }
    },
    "outputId": "dda4a00b-5e49-4ea3-ad1e-bacb349e0f34"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-9d8a0bce-14b7-4fbb-8b38-3a54e7032dee\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-9d8a0bce-14b7-4fbb-8b38-3a54e7032dee\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Saving leao 9.txt to leao 9.txt\n",
      "Saving leão 10.txt to leão 10.txt\n",
      "Saving leao 11.txt to leao 11.txt\n",
      "Saving leão 12.txt to leão 12.txt\n",
      "Saving leão 13.txt to leão 13.txt\n",
      "Saving leão 14.txt to leão 14.txt\n",
      "Saving leão 15.txt to leão 15.txt\n",
      "Saving leão 16.txt to leão 16.txt\n",
      "Saving leão 17.txt to leão 17.txt\n",
      "Saving leão 18.txt to leão 18.txt\n",
      "Saving leao 19.txt to leao 19.txt\n",
      "Saving leão 20.txt to leão 20.txt\n",
      "Saving leão 21.txt to leão 21.txt\n",
      "Saving leão 22.txt to leão 22.txt\n",
      "Saving leao 23.txt to leao 23.txt\n",
      "Saving leão 24.txt to leão 24.txt\n",
      "Saving leão 25.txt to leão 25.txt\n",
      "Saving leão 26.txt to leão 26.txt\n",
      "Saving leão 27.txt to leão 27.txt\n",
      "Saving leão 28.txt to leão 28.txt\n",
      "Saving leão 29.txt to leão 29.txt\n",
      "Saving leão 30.txt to leão 30.txt\n",
      "Saving leão 31.txt to leão 31.txt\n",
      "Saving leão 32.txt to leão 32.txt\n",
      "Saving leão 33.txt to leão 33.txt\n",
      "Saving leão 34.txt to leão 34.txt\n",
      "Saving leão 35.txt to leão 35.txt\n",
      "Saving leão 36.txt to leão 36.txt\n",
      "Saving leão 37.txt to leão 37.txt\n",
      "Saving leão 38.txt to leão 38.txt\n",
      "Saving leão 39.txt to leão 39.txt\n",
      "Saving leao 40.txt to leao 40.txt\n",
      "Saving tigre 9.txt to tigre 9.txt\n",
      "Saving tigre 10.txt to tigre 10.txt\n",
      "Saving tigre 11.txt to tigre 11.txt\n",
      "Saving tigre 12.txt to tigre 12.txt\n",
      "Saving tigre 13.txt to tigre 13.txt\n",
      "Saving tigre 14.txt to tigre 14.txt\n",
      "Saving tigre 15.txt to tigre 15.txt\n",
      "Saving tigre 16.txt to tigre 16.txt\n",
      "Saving tigre 17.txt to tigre 17.txt\n",
      "Saving tigre 18.txt to tigre 18.txt\n",
      "Saving tigre 19.txt to tigre 19.txt\n",
      "Saving tigre 20.txt to tigre 20.txt\n",
      "Saving tigre 21.txt to tigre 21.txt\n",
      "Saving tigre 22.txt to tigre 22.txt\n",
      "Saving tigre 23.txt to tigre 23.txt\n",
      "Saving tigre 24.txt to tigre 24.txt\n",
      "Saving tigre 25.txt to tigre 25.txt\n",
      "Saving tigre 26.txt to tigre 26.txt\n",
      "Saving tigre 27.txt to tigre 27.txt\n",
      "Saving tigre 28.txt to tigre 28.txt\n",
      "Saving tigre 29.txt to tigre 29.txt\n",
      "Saving tigre 30.txt to tigre 30.txt\n",
      "Saving tigre 31.txt to tigre 31.txt\n",
      "Saving tigre 32.txt to tigre 32.txt\n",
      "Saving tigre 33.txt to tigre 33.txt\n",
      "Saving tigre 34.txt to tigre 34.txt\n",
      "Saving tigre 35.txt to tigre 35.txt\n",
      "Saving tigre 36.txt to tigre 36.txt\n",
      "Saving tigre 37.txt to tigre 37.txt\n",
      "Saving tigre 38.txt to tigre 38.txt\n",
      "Saving tigre 39.txt to tigre 39.txt\n",
      "Saving tigre 40.txt to tigre 40.txt\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!mv nome_da_imagem.jpg /content/dataset_yolo/images/train/\n",
    "!mv nome_do_label.txt /content/dataset_yolo/labels/train/"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ahsZtEbh223a",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1760414709567,
     "user_tz": 180,
     "elapsed": 347,
     "user": {
      "displayName": "Maison Wendrel",
      "userId": "09937109300817250136"
     }
    },
    "outputId": "0a1c1483-95ae-4a03-ab87-deab6caa5c65"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "mv: cannot stat 'nome_da_imagem.jpg': No such file or directory\n",
      "mv: cannot stat 'nome_do_label.txt': No such file or directory\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Carregar o modelo pré-treinado YOLOv8n\n",
    "model = YOLO('yolov8n.pt')\n",
    "\n",
    "# Treinar o modelo\n",
    "model.train(\n",
    "    data='/content/dataset_yolo/data.yaml',\n",
    "    epochs=50,\n",
    "    imgsz=640,\n",
    "    batch=16\n",
    ")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "iVwslbom226H",
    "executionInfo": {
     "status": "error",
     "timestamp": 1760416089587,
     "user_tz": 180,
     "elapsed": 469,
     "user": {
      "displayName": "Maison Wendrel",
      "userId": "09937109300817250136"
     }
    },
    "outputId": "72719f42-73bc-4ff5-8072-5e8d1c8e7227"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Ultralytics 8.3.213 🚀 Python-3.12.12 torch-2.8.0+cu126 CPU (Intel Xeon CPU @ 2.20GHz)\n",
      "\u001B[34m\u001B[1mengine/trainer: \u001B[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/dataset_yolo/data.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=50, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train6, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/runs/detect/train6, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    751702  ultralytics.nn.modules.head.Detect           [2, [64, 128, 256]]           \n",
      "Model summary: 129 layers, 3,011,238 parameters, 3,011,222 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "FileNotFoundError",
     "evalue": "\u001B[34m\u001B[1mtrain: \u001B[0mError loading data from /content/dataset_yolo/images/train\nSee https://docs.ultralytics.com/datasets for dataset formatting guidance.",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/data/base.py\u001B[0m in \u001B[0;36mget_img_files\u001B[0;34m(self, img_path)\u001B[0m\n\u001B[1;32m    179\u001B[0m             \u001B[0;31m# self.img_files = sorted([x for x in f if x.suffix[1:].lower() in IMG_FORMATS])  # pathlib\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 180\u001B[0;31m             \u001B[0;32massert\u001B[0m \u001B[0mim_files\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34mf\"{self.prefix}No images found in {img_path}. {FORMATS_HELP_MSG}\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    181\u001B[0m         \u001B[0;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mAssertionError\u001B[0m: \u001B[34m\u001B[1mtrain: \u001B[0mNo images found in /content/dataset_yolo/images/train. Supported formats are:\nimages: {'tiff', 'png', 'webp', 'jpg', 'bmp', 'dng', 'heic', 'tif', 'pfm', 'jpeg', 'mpo'}\nvideos: {'gif', 'wmv', 'webm', 'mpg', 'asf', 'avi', 'mkv', 'ts', 'mpeg', 'm4v', 'mov', 'mp4'}",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipython-input-2825074745.py\u001B[0m in \u001B[0;36m<cell line: 0>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;31m# Treinar o modelo\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 5\u001B[0;31m model.train(\n\u001B[0m\u001B[1;32m      6\u001B[0m     \u001B[0mdata\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'/content/dataset_yolo/data.yaml'\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      7\u001B[0m     \u001B[0mepochs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m50\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/engine/model.py\u001B[0m in \u001B[0;36mtrain\u001B[0;34m(self, trainer, **kwargs)\u001B[0m\n\u001B[1;32m    798\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmodel\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrainer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    799\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 800\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrainer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrain\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    801\u001B[0m         \u001B[0;31m# Update model and cfg after training\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    802\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mRANK\u001B[0m \u001B[0;32min\u001B[0m \u001B[0;34m{\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m}\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/engine/trainer.py\u001B[0m in \u001B[0;36mtrain\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    234\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    235\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 236\u001B[0;31m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_do_train\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    237\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    238\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_setup_scheduler\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/engine/trainer.py\u001B[0m in \u001B[0;36m_do_train\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    355\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mworld_size\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    356\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_setup_ddp\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 357\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_setup_train\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    358\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    359\u001B[0m         \u001B[0mnb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrain_loader\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# number of batches\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/engine/trainer.py\u001B[0m in \u001B[0;36m_setup_train\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    314\u001B[0m         \u001B[0;31m# Dataloaders\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    315\u001B[0m         \u001B[0mbatch_size\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbatch_size\u001B[0m \u001B[0;34m//\u001B[0m \u001B[0mmax\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mworld_size\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 316\u001B[0;31m         self.train_loader = self.get_dataloader(\n\u001B[0m\u001B[1;32m    317\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"train\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbatch_size\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mbatch_size\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrank\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mLOCAL_RANK\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmode\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"train\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    318\u001B[0m         )\n",
      "\u001B[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/models/yolo/detect/train.py\u001B[0m in \u001B[0;36mget_dataloader\u001B[0;34m(self, dataset_path, batch_size, rank, mode)\u001B[0m\n\u001B[1;32m     95\u001B[0m         \u001B[0;32massert\u001B[0m \u001B[0mmode\u001B[0m \u001B[0;32min\u001B[0m \u001B[0;34m{\u001B[0m\u001B[0;34m\"train\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"val\"\u001B[0m\u001B[0;34m}\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34mf\"Mode must be 'train' or 'val', not {mode}.\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     96\u001B[0m         \u001B[0;32mwith\u001B[0m \u001B[0mtorch_distributed_zero_first\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mrank\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m  \u001B[0;31m# init dataset *.cache only once if DDP\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 97\u001B[0;31m             \u001B[0mdataset\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbuild_dataset\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdataset_path\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmode\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbatch_size\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     98\u001B[0m         \u001B[0mshuffle\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmode\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;34m\"train\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     99\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mgetattr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdataset\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"rect\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;32mFalse\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0mshuffle\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/models/yolo/detect/train.py\u001B[0m in \u001B[0;36mbuild_dataset\u001B[0;34m(self, img_path, mode, batch)\u001B[0m\n\u001B[1;32m     78\u001B[0m         \"\"\"\n\u001B[1;32m     79\u001B[0m         \u001B[0mgs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmax\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0munwrap_model\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstride\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmax\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmodel\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m32\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 80\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mbuild_yolo_dataset\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mimg_path\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbatch\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmode\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mmode\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrect\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mmode\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;34m\"val\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstride\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mgs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     81\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     82\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mget_dataloader\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdataset_path\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mstr\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbatch_size\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mint\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m16\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrank\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mint\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmode\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mstr\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m\"train\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/data/build.py\u001B[0m in \u001B[0;36mbuild_yolo_dataset\u001B[0;34m(cfg, img_path, batch, data, mode, rect, stride, multi_modal)\u001B[0m\n\u001B[1;32m    132\u001B[0m     \u001B[0;34m\"\"\"Build and return a YOLO dataset based on configuration parameters.\"\"\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    133\u001B[0m     \u001B[0mdataset\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mYOLOMultiModalDataset\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mmulti_modal\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0mYOLODataset\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 134\u001B[0;31m     return dataset(\n\u001B[0m\u001B[1;32m    135\u001B[0m         \u001B[0mimg_path\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mimg_path\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    136\u001B[0m         \u001B[0mimgsz\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mcfg\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mimgsz\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/data/dataset.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, data, task, *args, **kwargs)\u001B[0m\n\u001B[1;32m     88\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdata\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     89\u001B[0m         \u001B[0;32massert\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0muse_segments\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0muse_keypoints\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"Can not use both segments and keypoints.\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 90\u001B[0;31m         \u001B[0msuper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__init__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mchannels\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"channels\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m3\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     91\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     92\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mcache_labels\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpath\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mPath\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mPath\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"./labels.cache\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mdict\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/data/base.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, img_path, imgsz, cache, augment, hyp, prefix, rect, batch_size, stride, pad, single_cls, classes, fraction, channels)\u001B[0m\n\u001B[1;32m    115\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mchannels\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mchannels\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    116\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcv2_flag\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcv2\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mIMREAD_GRAYSCALE\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mchannels\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;36m1\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0mcv2\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mIMREAD_COLOR\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 117\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mim_files\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_img_files\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mimg_path\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    118\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlabels\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_labels\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    119\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mupdate_labels\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minclude_class\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mclasses\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# single_cls and include_class\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/data/base.py\u001B[0m in \u001B[0;36mget_img_files\u001B[0;34m(self, img_path)\u001B[0m\n\u001B[1;32m    180\u001B[0m             \u001B[0;32massert\u001B[0m \u001B[0mim_files\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34mf\"{self.prefix}No images found in {img_path}. {FORMATS_HELP_MSG}\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    181\u001B[0m         \u001B[0;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 182\u001B[0;31m             \u001B[0;32mraise\u001B[0m \u001B[0mFileNotFoundError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34mf\"{self.prefix}Error loading data from {img_path}\\n{HELP_URL}\"\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    183\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfraction\u001B[0m \u001B[0;34m<\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    184\u001B[0m             \u001B[0mim_files\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mim_files\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mround\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mim_files\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m*\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfraction\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m]\u001B[0m  \u001B[0;31m# retain a fraction of the dataset\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: \u001B[34m\u001B[1mtrain: \u001B[0mError loading data from /content/dataset_yolo/images/train\nSee https://docs.ultralytics.com/datasets for dataset formatting guidance."
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "metrics = model.val(data='/content/dataset_yolo/data.yaml')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 547
    },
    "id": "HtewAfwD229K",
    "executionInfo": {
     "status": "error",
     "timestamp": 1760416283625,
     "user_tz": 180,
     "elapsed": 150,
     "user": {
      "displayName": "Maison Wendrel",
      "userId": "09937109300817250136"
     }
    },
    "outputId": "7021f61b-0822-4002-a56c-0ed6a3e292a0"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Ultralytics 8.3.213 🚀 Python-3.12.12 torch-2.8.0+cu126 CPU (Intel Xeon CPU @ 2.20GHz)\n",
      "Model summary (fused): 72 layers, 3,006,038 parameters, 12,870 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "FileNotFoundError",
     "evalue": "\u001B[34m\u001B[1mval: \u001B[0mError loading data from /content/dataset_yolo/images/val\nSee https://docs.ultralytics.com/datasets for dataset formatting guidance.",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/data/base.py\u001B[0m in \u001B[0;36mget_img_files\u001B[0;34m(self, img_path)\u001B[0m\n\u001B[1;32m    179\u001B[0m             \u001B[0;31m# self.img_files = sorted([x for x in f if x.suffix[1:].lower() in IMG_FORMATS])  # pathlib\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 180\u001B[0;31m             \u001B[0;32massert\u001B[0m \u001B[0mim_files\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34mf\"{self.prefix}No images found in {img_path}. {FORMATS_HELP_MSG}\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    181\u001B[0m         \u001B[0;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mAssertionError\u001B[0m: \u001B[34m\u001B[1mval: \u001B[0mNo images found in /content/dataset_yolo/images/val. Supported formats are:\nimages: {'tiff', 'png', 'webp', 'jpg', 'bmp', 'dng', 'heic', 'tif', 'pfm', 'jpeg', 'mpo'}\nvideos: {'gif', 'wmv', 'webm', 'mpg', 'asf', 'avi', 'mkv', 'ts', 'mpeg', 'm4v', 'mov', 'mp4'}",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipython-input-3630030931.py\u001B[0m in \u001B[0;36m<cell line: 0>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mmetrics\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mval\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'/content/dataset_yolo/data.yaml'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/engine/model.py\u001B[0m in \u001B[0;36mval\u001B[0;34m(self, validator, **kwargs)\u001B[0m\n\u001B[1;32m    633\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    634\u001B[0m         \u001B[0mvalidator\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mvalidator\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_smart_load\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"validator\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0m_callbacks\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcallbacks\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 635\u001B[0;31m         \u001B[0mvalidator\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    636\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmetrics\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mvalidator\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmetrics\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    637\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mvalidator\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmetrics\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\u001B[0m in \u001B[0;36mdecorate_context\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    118\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mdecorate_context\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    119\u001B[0m         \u001B[0;32mwith\u001B[0m \u001B[0mctx_factory\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 120\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    121\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    122\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mdecorate_context\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/engine/validator.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, trainer, model)\u001B[0m\n\u001B[1;32m    186\u001B[0m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrect\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mFalse\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    187\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstride\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstride\u001B[0m  \u001B[0;31m# used in get_dataloader() for padding\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 188\u001B[0;31m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdataloader\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdataloader\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_dataloader\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msplit\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbatch\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    189\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    190\u001B[0m             \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0meval\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/models/yolo/detect/val.py\u001B[0m in \u001B[0;36mget_dataloader\u001B[0;34m(self, dataset_path, batch_size)\u001B[0m\n\u001B[1;32m    299\u001B[0m             \u001B[0;34m(\u001B[0m\u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mutils\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mDataLoader\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mDataloader\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mvalidation\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    300\u001B[0m         \"\"\"\n\u001B[0;32m--> 301\u001B[0;31m         \u001B[0mdataset\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbuild_dataset\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdataset_path\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbatch\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mbatch_size\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmode\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"val\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    302\u001B[0m         return build_dataloader(\n\u001B[1;32m    303\u001B[0m             \u001B[0mdataset\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbatch_size\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mworkers\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mshuffle\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrank\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdrop_last\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcompile\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/models/yolo/detect/val.py\u001B[0m in \u001B[0;36mbuild_dataset\u001B[0;34m(self, img_path, mode, batch)\u001B[0m\n\u001B[1;32m    286\u001B[0m             \u001B[0;34m(\u001B[0m\u001B[0mDataset\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mYOLO\u001B[0m \u001B[0mdataset\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    287\u001B[0m         \"\"\"\n\u001B[0;32m--> 288\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mbuild_yolo_dataset\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mimg_path\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbatch\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmode\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mmode\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstride\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstride\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    289\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    290\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mget_dataloader\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdataset_path\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mstr\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbatch_size\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mint\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mutils\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mDataLoader\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/data/build.py\u001B[0m in \u001B[0;36mbuild_yolo_dataset\u001B[0;34m(cfg, img_path, batch, data, mode, rect, stride, multi_modal)\u001B[0m\n\u001B[1;32m    132\u001B[0m     \u001B[0;34m\"\"\"Build and return a YOLO dataset based on configuration parameters.\"\"\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    133\u001B[0m     \u001B[0mdataset\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mYOLOMultiModalDataset\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mmulti_modal\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0mYOLODataset\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 134\u001B[0;31m     return dataset(\n\u001B[0m\u001B[1;32m    135\u001B[0m         \u001B[0mimg_path\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mimg_path\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    136\u001B[0m         \u001B[0mimgsz\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mcfg\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mimgsz\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/data/dataset.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, data, task, *args, **kwargs)\u001B[0m\n\u001B[1;32m     88\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdata\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     89\u001B[0m         \u001B[0;32massert\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0muse_segments\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0muse_keypoints\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"Can not use both segments and keypoints.\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 90\u001B[0;31m         \u001B[0msuper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__init__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mchannels\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"channels\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m3\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     91\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     92\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mcache_labels\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpath\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mPath\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mPath\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"./labels.cache\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mdict\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/data/base.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, img_path, imgsz, cache, augment, hyp, prefix, rect, batch_size, stride, pad, single_cls, classes, fraction, channels)\u001B[0m\n\u001B[1;32m    115\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mchannels\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mchannels\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    116\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcv2_flag\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcv2\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mIMREAD_GRAYSCALE\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mchannels\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;36m1\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0mcv2\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mIMREAD_COLOR\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 117\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mim_files\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_img_files\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mimg_path\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    118\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlabels\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_labels\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    119\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mupdate_labels\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minclude_class\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mclasses\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# single_cls and include_class\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/data/base.py\u001B[0m in \u001B[0;36mget_img_files\u001B[0;34m(self, img_path)\u001B[0m\n\u001B[1;32m    180\u001B[0m             \u001B[0;32massert\u001B[0m \u001B[0mim_files\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34mf\"{self.prefix}No images found in {img_path}. {FORMATS_HELP_MSG}\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    181\u001B[0m         \u001B[0;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 182\u001B[0;31m             \u001B[0;32mraise\u001B[0m \u001B[0mFileNotFoundError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34mf\"{self.prefix}Error loading data from {img_path}\\n{HELP_URL}\"\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    183\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfraction\u001B[0m \u001B[0;34m<\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    184\u001B[0m             \u001B[0mim_files\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mim_files\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mround\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mim_files\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m*\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfraction\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m]\u001B[0m  \u001B[0;31m# retain a fraction of the dataset\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: \u001B[34m\u001B[1mval: \u001B[0mError loading data from /content/dataset_yolo/images/val\nSee https://docs.ultralytics.com/datasets for dataset formatting guidance."
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "results = model.predict(source='/content/dataset_yolo/images/test', save=True)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "id": "kDUJEZGK3k8c",
    "executionInfo": {
     "status": "error",
     "timestamp": 1760415995604,
     "user_tz": 180,
     "elapsed": 24,
     "user": {
      "displayName": "Maison Wendrel",
      "userId": "09937109300817250136"
     }
    },
    "outputId": "3d827b47-8dd8-4030-c182-f7c0b60523f7"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "FileNotFoundError",
     "evalue": "No images or videos found in /content/dataset_yolo/images/test. Supported formats are:\nimages: {'tiff', 'png', 'webp', 'jpg', 'bmp', 'dng', 'heic', 'tif', 'pfm', 'jpeg', 'mpo'}\nvideos: {'gif', 'wmv', 'webm', 'mpg', 'asf', 'avi', 'mkv', 'ts', 'mpeg', 'm4v', 'mov', 'mp4'}",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipython-input-1916520524.py\u001B[0m in \u001B[0;36m<cell line: 0>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mresults\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msource\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'/content/dataset_yolo/images/test'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msave\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/engine/model.py\u001B[0m in \u001B[0;36mpredict\u001B[0;34m(self, source, stream, predictor, **kwargs)\u001B[0m\n\u001B[1;32m    555\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mprompts\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0mhasattr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpredictor\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"set_prompts\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m  \u001B[0;31m# for SAM-type models\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    556\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpredictor\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mset_prompts\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mprompts\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 557\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpredictor\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpredict_cli\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msource\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0msource\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mis_cli\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpredictor\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msource\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0msource\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstream\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mstream\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    558\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    559\u001B[0m     def track(\n",
      "\u001B[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/engine/predictor.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, source, model, stream, *args, **kwargs)\u001B[0m\n\u001B[1;32m    227\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstream_inference\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msource\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    228\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 229\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mlist\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstream_inference\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msource\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# merge list of Result into one\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    230\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    231\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mpredict_cli\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msource\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\u001B[0m in \u001B[0;36mgenerator_context\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     36\u001B[0m             \u001B[0;31m# Issuing `None` to a generator fires it up\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     37\u001B[0m             \u001B[0;32mwith\u001B[0m \u001B[0mctx_factory\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 38\u001B[0;31m                 \u001B[0mresponse\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mgen\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     39\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     40\u001B[0m             \u001B[0;32mwhile\u001B[0m \u001B[0;32mTrue\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/engine/predictor.py\u001B[0m in \u001B[0;36mstream_inference\u001B[0;34m(self, source, model, *args, **kwargs)\u001B[0m\n\u001B[1;32m    304\u001B[0m         \u001B[0;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_lock\u001B[0m\u001B[0;34m:\u001B[0m  \u001B[0;31m# for thread-safe inference\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    305\u001B[0m             \u001B[0;31m# Setup source every time predict is called\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 306\u001B[0;31m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msetup_source\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msource\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0msource\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msource\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    307\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    308\u001B[0m             \u001B[0;31m# Check if save_dir/ label file exists\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/engine/predictor.py\u001B[0m in \u001B[0;36msetup_source\u001B[0;34m(self, source)\u001B[0m\n\u001B[1;32m    259\u001B[0m         \"\"\"\n\u001B[1;32m    260\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mimgsz\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcheck_imgsz\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mimgsz\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstride\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstride\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmin_dim\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m2\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# check image size\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 261\u001B[0;31m         self.dataset = load_inference_source(\n\u001B[0m\u001B[1;32m    262\u001B[0m             \u001B[0msource\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0msource\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    263\u001B[0m             \u001B[0mbatch\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbatch\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/data/build.py\u001B[0m in \u001B[0;36mload_inference_source\u001B[0;34m(source, batch, vid_stride, buffer, channels)\u001B[0m\n\u001B[1;32m    308\u001B[0m         \u001B[0mdataset\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mLoadPilAndNumpy\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msource\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mchannels\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mchannels\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    309\u001B[0m     \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 310\u001B[0;31m         \u001B[0mdataset\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mLoadImagesAndVideos\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msource\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbatch\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mbatch\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvid_stride\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mvid_stride\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mchannels\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mchannels\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    311\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    312\u001B[0m     \u001B[0;31m# Attach source types to the dataset\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/data/loaders.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, path, batch, vid_stride, channels)\u001B[0m\n\u001B[1;32m    399\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcap\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    400\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnf\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 401\u001B[0;31m             \u001B[0;32mraise\u001B[0m \u001B[0mFileNotFoundError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34mf\"No images or videos found in {p}. {FORMATS_HELP_MSG}\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    402\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    403\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__iter__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: No images or videos found in /content/dataset_yolo/images/test. Supported formats are:\nimages: {'tiff', 'png', 'webp', 'jpg', 'bmp', 'dng', 'heic', 'tif', 'pfm', 'jpeg', 'mpo'}\nvideos: {'gif', 'wmv', 'webm', 'mpg', 'asf', 'avi', 'mkv', 'ts', 'mpeg', 'm4v', 'mov', 'mp4'}"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "model.export(format='pt')  # Exporta como PyTorch (.pt)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 263
    },
    "id": "db2aYhhP3wHi",
    "executionInfo": {
     "status": "error",
     "timestamp": 1760416009148,
     "user_tz": 180,
     "elapsed": 14,
     "user": {
      "displayName": "Maison Wendrel",
      "userId": "09937109300817250136"
     }
    },
    "outputId": "165d9e0c-66d2-4459-d5bd-8f17ebb05501"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "'IterableSimpleNamespace' object is not subscriptable",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipython-input-4272425615.py\u001B[0m in \u001B[0;36m<cell line: 0>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexport\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mformat\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'pt'\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# Exporta como PyTorch (.pt)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/engine/model.py\u001B[0m in \u001B[0;36mexport\u001B[0;34m(self, **kwargs)\u001B[0m\n\u001B[1;32m    727\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    728\u001B[0m         custom = {\n\u001B[0;32m--> 729\u001B[0;31m             \u001B[0;34m\"imgsz\"\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"imgsz\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    730\u001B[0m             \u001B[0;34m\"batch\"\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    731\u001B[0m             \u001B[0;34m\"data\"\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mTypeError\u001B[0m: 'IterableSimpleNamespace' object is not subscriptable"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!cat /content/dataset_yolo/data.yaml"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aWdetlJj5odx",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1760416047104,
     "user_tz": 180,
     "elapsed": 44,
     "user": {
      "displayName": "Maison Wendrel",
      "userId": "09937109300817250136"
     }
    },
    "outputId": "f7adc14e-755f-48f1-bf6a-2a931dbbf233"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "names:\n",
      "- A\n",
      "- B\n",
      "nc: 2\n",
      "test: /content/dataset_yolo/images/test\n",
      "train: /content/dataset_yolo/images/train\n",
      "val: /content/dataset_yolo/images/val\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from IPython.display import Image, display\n",
    "display(Image(filename='runs/detect/predict/image1.jpg'))  # substitua pelo nome real da imagem"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 304
    },
    "id": "aCtY_mxA51UW",
    "executionInfo": {
     "status": "error",
     "timestamp": 1760416039403,
     "user_tz": 180,
     "elapsed": 16,
     "user": {
      "displayName": "Maison Wendrel",
      "userId": "09937109300817250136"
     }
    },
    "outputId": "20f8caa3-2363-4fb0-e0cc-159bba46b338"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "error",
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'runs/detect/predict/image1.jpg'",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipython-input-4189158072.py\u001B[0m in \u001B[0;36m<cell line: 0>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mIPython\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdisplay\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mImage\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdisplay\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m \u001B[0mdisplay\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mImage\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfilename\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'runs/detect/predict/image1.jpg'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# substitua pelo nome real da imagem\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/display.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, data, url, filename, format, embed, width, height, retina, unconfined, metadata)\u001B[0m\n\u001B[1;32m   1229\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mretina\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mretina\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1230\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0munconfined\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0munconfined\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1231\u001B[0;31m         super(Image, self).__init__(data=data, url=url, filename=filename, \n\u001B[0m\u001B[1;32m   1232\u001B[0m                 metadata=metadata)\n\u001B[1;32m   1233\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/display.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, data, url, filename, metadata)\u001B[0m\n\u001B[1;32m    635\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmetadata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m{\u001B[0m\u001B[0;34m}\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    636\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 637\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreload\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    638\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_check_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    639\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/display.py\u001B[0m in \u001B[0;36mreload\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1261\u001B[0m         \u001B[0;34m\"\"\"Reload the raw data from file or URL.\"\"\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1262\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0membed\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1263\u001B[0;31m             \u001B[0msuper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mImage\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreload\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1264\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mretina\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1265\u001B[0m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_retina_shape\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/display.py\u001B[0m in \u001B[0;36mreload\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    660\u001B[0m         \u001B[0;34m\"\"\"Reload the raw data from file or URL.\"\"\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    661\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfilename\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 662\u001B[0;31m             \u001B[0;32mwith\u001B[0m \u001B[0mopen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfilename\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_read_flags\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    663\u001B[0m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mread\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    664\u001B[0m         \u001B[0;32melif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0murl\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'runs/detect/predict/image1.jpg'"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aFYV59xp6Ube",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1760416029350,
     "user_tz": 180,
     "elapsed": 1786,
     "user": {
      "displayName": "Maison Wendrel",
      "userId": "09937109300817250136"
     }
    },
    "outputId": "f235452d-ff23-4cc0-a046-0909ffb1a55e"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!\"show_random_image\"('/content/dataset_yolo/images/test')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FkJidF8G6uwv",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1760416032114,
     "user_tz": 180,
     "elapsed": 100,
     "user": {
      "displayName": "Maison Wendrel",
      "userId": "09937109300817250136"
     }
    },
    "outputId": "e1a4d1c4-48cb-4616-eeb3-96502d10a6f5"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/bin/bash: -c: line 1: syntax error near unexpected token `'/content/dataset_yolo/images/test''\n",
      "/bin/bash: -c: line 1: `\"show_random_image\"('/content/dataset_yolo/images/test')'\n"
     ]
    }
   ]
  }
 ]
}
